import torch
import random
import numpy as np
from collections import deque
from GameAI import SnakeGameAI, Direction, Point
from Model import Linear_QNet, QTrainer
from Helper import plot

max_memory = 100000
batch_size = 1000
lr = 0.001

class Agent:
    def __init__(self):
        self.n_games = 0
        self.epsilon = 0
        # discount rate
        self.gamma = 0.9
        self.memory = deque(maxlen=max_memory)
        self.model = Linear_QNet(11, 256, 3)
        self.trainer = QTrainer(self.model, lr=lr, gamma=self.gamma)
        self.model.load_state_dict(torch.load('./model/model7.pth'))
        self.model.eval()
        self.wp = True
    def get_state(self, game):
        head = game.snake[0]
        point_left = Point(head.x - 30, head.y)
        point_right = Point(head.x + 30, head.y)
        point_up = Point(head.x, head.y - 30)
        point_down = Point(head.x, head.y + 30)
        direction_left = game.direction == Direction.LEFT
        direction_right = game.direction == Direction.RIGHT
        direction_up = game.direction == Direction.UP
        direction_down = game.direction == Direction.DOWN
        state = [
            # DANGER STRAIGHT
            (direction_left and game.is_collision(point_left)) or
            (direction_right and game.is_collision(point_right)) or
            (direction_up and game.is_collision(point_up)) or
            (direction_down and game.is_collision(point_down)),
            # DANGER LEFT
            (direction_left and game.is_collision(point_down)) or
            (direction_right and game.is_collision(point_up)) or
            (direction_up and game.is_collision(point_left)) or
            (direction_down and game.is_collision(point_right)),
            # DANGER RIGHT
            (direction_left and game.is_collision(point_up)) or
            (direction_right and game.is_collision(point_down)) or
            (direction_up and game.is_collision(point_right)) or
            (direction_down and game.is_collision(point_left)),
            # MOVE DIRECTION
            # one is True and three are always False
            direction_left,
            direction_right,
            direction_up,
            direction_down,
            # FOOD LOCATION
            # 2 van onderstaande worden dus altijd True en twee worden er False
            game.food.x < game.head.x,  # food left
            game.food.x > game.head.x,  # food right
            game.food.y < game.head.y,  # food up
            game.food.y > game.head.y  # food down
        ]
        return np.array(state, dtype=int)
    def get_state_mod(self, game):
        head = game.snake[0]
        point_left = Point(head.x - 30, head.y)
        point_right = Point(head.x + 30, head.y)
        point_up = Point(head.x, head.y - 30)
        point_down = Point(head.x, head.y + 30)
        direction_left = game.direction == Direction.LEFT
        direction_right = game.direction == Direction.RIGHT
        direction_up = game.direction == Direction.UP
        direction_down = game.direction == Direction.DOWN
        # NN to Algo transition
        if self.wp:
            waypoint = Point(480, 450)
            if head.x == 480 and head.y == 450:
                self.wp = False
        else:
            waypoint = Point(30, 450)
        state = [
            # DANGER STRAIGHT
            (direction_left and game.is_collision(point_left)) or
            (direction_right and game.is_collision(point_right)) or
            (direction_up and game.is_collision(point_up)) or
            (direction_down and game.is_collision(point_down)),
            # DANGER LEFT
            (direction_left and game.is_collision(point_down)) or
            (direction_right and game.is_collision(point_up)) or
            (direction_up and game.is_collision(point_left)) or
            (direction_down and game.is_collision(point_right)),
            # DANGER RIGHT
            (direction_left and game.is_collision(point_up)) or
            (direction_right and game.is_collision(point_down)) or
            (direction_up and game.is_collision(point_right)) or
            (direction_down and game.is_collision(point_left)),
            # MOVE DIRECTION
            direction_left,
            direction_right,
            direction_up,
            direction_down,
            # FOOD LOCATION
            waypoint.x < game.head.x,  # food left
            waypoint.x > game.head.x,  # food right
            waypoint.y < game.head.y,  # food up
            waypoint.y > game.head.y  # food down
        ]
        return np.array(state, dtype=int)


    def remember(self, state, action, reward, next_state, game_over):
        self.memory.append((state, action, reward, next_state, game_over))


    def train_long_memory(self):
        # With speed = 20 it takes 50 sec.
        if len(self.memory) > batch_size:
            mini_sample = random.sample(self.memory, batch_size)
        else:
            mini_sample = self.memory
        states, actions, rewards, next_states, game_overs = zip(*mini_sample)
        self.trainer.train_step(states, actions, rewards, next_states, game_overs)

    def train_short_memory(self, state, action, reward, next_state, game_over):
        self.trainer.train_step(state, action, reward, next_state, game_over)

    def get_action(self, state):
        self.epsilon = 0 - self.n_games
        final_move = [0, 0, 0]
        if random.randint(0, 200) < self.epsilon:
            move = random.randint(0, 2)
            final_move[move] = 1
        else:
            # Makes it compatible
            state0 = torch.tensor(state, dtype=torch.float)
            prediction = self.model(state0)
            # sample return: [5.3, 2, 0.3]
            move = torch.argmax(prediction).item()
            final_move[move] = 1
        return final_move

# You can also make your own grid!
grid = [[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
        [-1, 135, 136, 139, 140, 143, 144, 147, 148, 153, 154, 159, 160, 161, 162, 163, 174, 175, -1],
        [-1, 134, 137, 138, 141, 142, 145, 146, 149, 152, 155, 158, 167, 166, 165, 164, 173, 176, -1],
        [-1, 133, 132, 131, 114, 113, 112, 111, 150, 151, 156, 157, 168, 169, 170, 171, 172, 177, -1],
        [-1, 128, 129, 130, 115, 108, 109, 110, 95, 94, 93, 92, 91, 90, 89, 88, 179, 178, -1],
        [-1, 127, 126, 125, 116, 107, 106, 105, 96, 5, 6, 7, 20, 21, 86, 87, 180, 181, -1],
        [-1, 122, 123, 124, 117, 102, 103, 104, 97, 4, 9, 8, 19, 22, 85, 84, 183, 182, -1],
        [-1, 121, 120, 119, 118, 101, 100, 99, 98, 3, 10, 11, 18, 23, 82, 83, 184, 185, -1],
        [-1, 262, 263, 266, 267, 268, 269, 270, 271, 2, 13, 12, 17, 24, 81, 80, 187, 186, -1],
        [-1, 261, 264, 265, 54, 53, 52, 51, 0, 1, 14, 15, 16, 25, 78, 79, 188, 189, -1],
        [-1, 260, 259, 258, 55, 56, 57, 50, 43, 42, 31, 30, 27, 26, 77, 192, 191, 190, -1],
        [-1, 255, 256, 257, 60, 59, 58, 49, 44, 41, 32, 29, 28, 75, 76, 193, 194, 195, -1],
        [-1, 254, 253, 252, 61, 62, 63, 48, 45, 40, 33, 34, 35, 74, 199, 198, 197, 196, -1],
        [-1, 249, 250, 251, 236, 235, 64, 47, 46, 39, 38, 37, 36, 73, 200, 201, 202, 203, -1],
        [-1, 248, 247, 246, 237, 234, 65, 66, 67, 68, 69, 70, 71, 72, 211, 210, 209, 204, -1],
        [-1, 243, 244, 245, 238, 233, 230, 229, 226, 225, 222, 221, 218, 217, 212, 213, 208, 205, -1],
        [-1, 242, 241, 240, 239, 232, 231, 228, 227, 224, 223, 220, 219, 216, 215, 214, 207, 206, -1],
        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]

highest = max(max(grid))
def best_step(x_head, y_head, pos, food_pos, tail_pos, game_dir):
    options = []
    move = "nothing"
    left = grid[int(y_head)][int(x_head-1)]
    right = grid[int(y_head)][int(x_head+1)]
    up = grid[int(y_head-1)][int(x_head)]
    down = grid[int(y_head+1)][int(x_head)]
    # A
    if tail_pos > pos:
        # 1
        if food_pos > pos:
            if left > pos and left < food_pos and left < tail_pos and left > pos:
                if game_dir != Direction.RIGHT and left != -1:
                    options.append(left)
            if up > pos and up < food_pos and up < tail_pos and up > pos:
                if game_dir != Direction.DOWN and up != -1:
                    options.append(up)
            if right > pos and right < food_pos and right < tail_pos and right > pos:
                if game_dir != Direction.LEFT and right != -1:
                    options.append(right)
            if down > pos and down < food_pos and down < tail_pos and down > pos:
                if game_dir != Direction.UP and down != -1:
                    options.append(down)
            # best
            if len(options) != 0:
                move = max(options)
        # 2
        elif food_pos < pos:
            if left > pos:
                if game_dir != Direction.RIGHT and left != -1 and left < tail_pos and left > pos:
                    options.append(left)
            if up > pos:
                if game_dir != Direction.DOWN and up != -1 and up < tail_pos and up > pos:
                    options.append(up)
            if right > pos:
                if game_dir != Direction.LEFT and right != -1 and right < tail_pos and right > pos:
                    options.append(right)
            if down > pos:
                if game_dir != Direction.UP and down != -1 and down < tail_pos and down > pos:
                    options.append(down)
            # best
            if len(options) != 0:
                move = max(options)
    # B
    elif tail_pos < pos:
        # 1
        if food_pos > pos:
            if left > pos and left < food_pos:
                if game_dir != Direction.RIGHT and left != -1:
                    options.append(left)
            if up > pos and up < food_pos:
                if game_dir != Direction.DOWN and up != -1:
                    options.append(up)
            if right > pos and right < food_pos:
                if game_dir != Direction.LEFT and right != -1:
                    options.append(right)
            if down > pos and down < food_pos:
                if game_dir != Direction.UP and down != -1:
                    options.append(down)
            # best
            if len(options) != 0:
                move = max(options)
        # 2
        elif food_pos < pos:
            if left > pos or left < food_pos:
                if left < tail_pos or left > pos:
                    if game_dir != Direction.RIGHT and left != -1:
                        options.append(left)
            if up > pos or up < food_pos:
                if up < tail_pos and up > pos:
                    if game_dir != Direction.DOWN and up != -1:
                        options.append(up)
            if right > pos or right < food_pos:
                if right < tail_pos or right > pos:
                    if game_dir != Direction.LEFT and right != -1:
                        options.append(right)
            if down > pos or down < food_pos:
                if down < tail_pos or down > pos:
                    if game_dir != Direction.UP and down != -1:
                        options.append(down)
            # best
            if len(options) != 0:
                if any(num < food_pos for num in options):
                    move = min(options)
                else:
                    move = max(options)
    # C
    # no move found then +1
    if move == "nothing":
        if pos == highest:
            if left == 0:
                move = left
            elif up == 0:
                move = up
            elif right == 0:
                move = right
            elif down == 0:
                move = down
        else:
            if left == pos + 1:
                move = left
            elif up == pos + 1:
                move = up
            elif right == pos + 1:
                move = right
            elif down == pos + 1:
                move = down

    if move == left:
        return "left"
    elif move == up:
        return "up"
    elif move == right:
        return "right"
    elif move == down:
        return "down"
    else:
        print("No move found!")

def savest_step(x_head, y_head, pos):
    move = "nothing"
    left = grid[int(y_head)][int(x_head-1)]
    right = grid[int(y_head)][int(x_head+1)]
    up = grid[int(y_head-1)][int(x_head)]
    down = grid[int(y_head+1)][int(x_head)]
    if pos == highest:
        if left == 0:
            move = left
        elif up == 0:
            move = up
        elif right == 0:
            move = right
        elif down == 0:
            move = down
    else:
        if left == pos + 1:
            move = left
        elif up == pos + 1:
            move = up
        elif right == pos + 1:
            move = right
        elif down == pos + 1:
            move = down
    if move == left:
        return "left"
    elif move == up:
        return "up"
    elif move == right:
        return "right"
    elif move == down:
        return "down"
    else:
        print("No move found!")

def train():
    breaker = 0
    plot_scores = []
    plot_mean_scores = []
    total_score = 0
    record = 268
    agent = Agent()
    game = SnakeGameAI()
    while True:
        run = True
        while run:
            state_old = agent.get_state(game)
            final_move = agent.get_action(state_old)
            reward, game_over, score = game.play_step(final_move)
            state_new = agent.get_state(game)
            agent.train_short_memory(state_old, final_move, reward, state_new, game_over)
            agent.remember(state_old, final_move, reward, state_new, game_over)
            if game_over:
                game.reset()
                agent.n_games = agent.n_games + 1
                agent.train_long_memory()
                if score > record:
                    record = score
                agent.model.save()
                print("Game", agent.n_games, "Score", score, "Record", record)
                plot_scores.append(score)
                total_score = total_score + score
                mean_score = total_score / agent.n_games
                plot_mean_scores.append(mean_score)
                plot(plot_scores, plot_mean_scores)
                run = False
            elif score == 18:  # target 18
                break

        while run:
            state_old = agent.get_state_mod(game)
            final_move = agent.get_action(state_old)
            reward, game_over, score = game.play_step(final_move)
            if game_over:
                game.reset()
                agent.n_games = agent.n_games + 1
                if score > record:
                    record = score
                print("Game", agent.n_games, "Score", score, "Record", record)
                plot_scores.append(score)
                total_score = total_score + score
                mean_score = total_score / agent.n_games
                plot_mean_scores.append(mean_score)
                plot(plot_scores, plot_mean_scores)
                run = False
            if breaker == 1 and game.head.x == 30 and game.head.y == 450:
                breaker = 0
                break
            if game.head.x == 480 and game.head.y == 450:
                breaker = breaker + 1

        while run:
            algo_move = [0, 0, 0]
            snake = game.snake
            # tail
            x_tail = snake[-1].x / 30 + 1
            y_tail = snake[-1].y / 30 + 1
            tail_pos = grid[int(y_tail)][int(x_tail)]
            tail_pos = tail_pos - 3
            if tail_pos < 0:
                if tail_pos == -1:
                    tail_pos = highest
                elif tail_pos == -2:
                    tail_pos = highest - 1
                elif tail_pos == -3:
                    tail_pos = highest - 2
            # food
            x_food = game.food.x / 30 + 1
            y_food = game.food.y / 30 + 1
            food_pos = grid[int(y_food)][int(x_food)]
            # head
            x_head = snake[0].x / 30 + 1
            y_head = snake[0].y / 30 + 1
            pos = grid[int(y_head)][int(x_head)]
            # answer
            dir = best_step(x_head, y_head, pos, food_pos, tail_pos, game.direction)
            if game.direction == Direction.LEFT:
                if dir == "left":
                    algo_move = [1, 0, 0]
                elif dir == "up":
                    algo_move = [0, 1, 0]
                elif dir == "down":
                    algo_move = [0, 0, 1]
            elif game.direction == Direction.RIGHT:
                if dir == "right":
                    algo_move = [1, 0, 0]
                elif dir == "up":
                    algo_move = [0, 0, 1]
                elif dir == "down":
                    algo_move = [0, 1, 0]
            elif game.direction == Direction.UP:
                if dir == "up":
                    algo_move = [1, 0, 0]
                elif dir == "left":
                    algo_move = [0, 0, 1]
                elif dir == "right":
                    algo_move = [0, 1, 0]
            elif game.direction == Direction.DOWN:
                if dir == "down":
                    algo_move = [1, 0, 0]
                elif dir == "left":
                    algo_move = [0, 1, 0]
                elif dir == "right":
                    algo_move = [0, 0, 1]
            reward, game_over, score = game.play_step(algo_move)
            if game_over:
                game.reset()
                agent.n_games = agent.n_games + 1
                if score > record:
                    record = score
                print("Game", agent.n_games, "Score", score, "Record", record)
                plot_scores.append(score)
                total_score = total_score + score
                mean_score = total_score / agent.n_games
                plot_mean_scores.append(mean_score)
                plot(plot_scores, plot_mean_scores)
                run = False
            elif score > highest * 0.81:  # 220
                break

        while run:
            algo_move = [0, 0, 0]
            snake = game.snake
            # head
            x_head = snake[0].x / 30 + 1
            y_head = snake[0].y / 30 + 1
            pos = grid[int(y_head)][int(x_head)]
            # answer
            dir = savest_step(x_head, y_head, pos)
            if game.direction == Direction.LEFT:
                if dir == "left":
                    algo_move = [1, 0, 0]
                elif dir == "up":
                    algo_move = [0, 1, 0]
                elif dir == "down":
                    algo_move = [0, 0, 1]
            elif game.direction == Direction.RIGHT:
                if dir == "right":
                    algo_move = [1, 0, 0]
                elif dir == "up":
                    algo_move = [0, 0, 1]
                elif dir == "down":
                    algo_move = [0, 1, 0]
            elif game.direction == Direction.UP:
                if dir == "up":
                    algo_move = [1, 0, 0]
                elif dir == "left":
                    algo_move = [0, 0, 1]
                elif dir == "right":
                    algo_move = [0, 1, 0]
            elif game.direction == Direction.DOWN:
                if dir == "down":
                    algo_move = [1, 0, 0]
                elif dir == "left":
                    algo_move = [0, 1, 0]
                elif dir == "right":
                    algo_move = [0, 0, 1]
            reward, game_over, score = game.play_step(algo_move)
            if game_over:
                game.reset()
                agent.n_games = agent.n_games + 1
                if score > record:
                    record = score
                print("Game", agent.n_games, "Score", score, "Record", record)
                plot_scores.append(score)
                total_score = total_score + score
                mean_score = total_score / agent.n_games
                plot_mean_scores.append(mean_score)
                plot(plot_scores, plot_mean_scores)
                run = False

if __name__ == '__main__':
    train()
